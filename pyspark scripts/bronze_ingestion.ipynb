{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4465da00-f786-46e3-b275-7cd16b978914",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95729024-37a1-4c33-8f18-fc5882eac0a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**SPARK STREAMING**\n",
    "-- we will read the data from the source to get the schema and assign it to (schema_entity) which we will use in streaming reading , Itâ€™s because Spark Structured Streaming refuses to \"Infer Schema\" on its own. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9f40553-ceee-4f00-9f15-03332baffc5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The reasons why Spark forces this:\n",
    "1-Stability: Streams are meant to run forever. If Spark \"guessed\" the schema every time a new file arrived, and one file had a slightly different format, the whole production pipeline would crash.\n",
    "\n",
    "2-Performance: Inferring a schema requires Spark to read the file twice (once to guess types, once to load). In a high-speed stream, that's too slow.\n",
    "\n",
    "3-The \"Contract\": By providing a schema, you are giving Spark a \"contract.\" You are saying: \"I guarantee the data will look like this.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2197c191-efd8-46fc-87c6-f88dc33cf675",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "entities=['customers','drivers','locations','payments','trips','vehicles']\n",
    "for entity in entities:\n",
    "\n",
    "        df_batch = spark.read.format('csv').option('header', True)\\\n",
    "        .option('inferSchema',True).\\\n",
    "        load(f\"/Volumes/transportation_service_company/source/source_data/{entity}\")\n",
    "\n",
    "\n",
    "        schema_entity=df_batch.schema\n",
    "\n",
    "\n",
    "        df = spark.readStream.format('csv') \\\n",
    "        .option('header', True).schema(schema_entity) \\\n",
    "        .load(f\"/Volumes/transportation_service_company/source/source_data/{entity}\")\n",
    "         \n",
    "\n",
    "        # Writing data to bronze layer and create a table on top of it\n",
    "        df.writeStream.format('delta')\\\n",
    "        .outputMode('append')\\\n",
    "        .option('checkpointLocation',f'/Volumes/transportation_service_company/bronze/checkpoints/{entity}')\\\n",
    "        .trigger(once=True).toTable(f'transportation_service_company.bronze.{entity}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1b71172-3a06-4d80-bc5d-aa5f20907579",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c97df886-5602-495e-b2f9-d7e0b7992374",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Workspace/Users/majedabdu29@gmail.com/Transportation_service_company\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "curent=os.getcwd()\n",
    "print(curent)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}